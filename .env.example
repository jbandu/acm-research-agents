# Database
DATABASE_URL=your_neon_postgres_connection_string_here

# LLM API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
XAI_API_KEY=your_xai_grok_api_key_here

# App Configuration
NEXT_PUBLIC_APP_NAME=ACM Research Agents
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Admin Secret (for migrations and admin endpoints)
ADMIN_SECRET=change-me-in-production

# NextAuth Configuration
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-nextauth-secret-here

# MCP WebSocket Server Configuration
# Token required for OpenAI Agent Builder to connect to the MCP server
MCP_SERVER_TOKEN=change-me-to-secure-random-string

# Webhook Configuration
# The MCP server forwards all tool calls to this webhook endpoint
WEBHOOK_URL=https://acm-pi-three.vercel.app/api/agent-webhook

# Optional: Bearer token for webhook authentication
# If set, the MCP server will include this in the Authorization header when calling the webhook
WEBHOOK_BEARER=
# Google Patents via SerpAPI (optional for patent intelligence)
SERPAPI_KEY=your_serpapi_key_here

# Ollama (Local LLM) - Optional
# Install from https://ollama.ai then run: ollama pull llama3.1:8b
# Enable local LLM (set to 'false' to disable, defaults to enabled)
ENABLE_OLLAMA=true
# Ollama API endpoint (defaults to http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
# Ollama model to use (defaults to llama3.1:8b)
# Options: llama3.1:8b, llama3.1:70b, mistral:7b, deepseek-coder, etc.
OLLAMA_MODEL=llama3.1:8b

# OpenAlex Academic Literature Search (Free, No API Key Required)
# Free academic search engine with 250M+ research papers
# API Docs: https://docs.openalex.org/
# Email for polite pool (higher rate limits: 100k requests/day vs 100k/day)
OPENALEX_EMAIL=your-email@example.com
# Enable caching to reduce API calls (set to 'true' to enable)
OPENALEX_CACHE_ENABLED=true
# Maximum results per search (default: 20)
OPENALEX_MAX_RESULTS_DEFAULT=20
