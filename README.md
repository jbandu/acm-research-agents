# ACM Research Agents Platform

Multi-LLM Research Agent Orchestration Platform for Cancer Research at ACM Biolabs.

Built by **Jayaprakash Bandu** - Precision AI Architect

## ğŸš€ Features

- **Parallel LLM Orchestration**: Query Claude Sonnet 4.5, GPT-4o, Gemini 1.5 Pro, and Grok 2 simultaneously
- **Consensus Detection**: Automatically identify agreement or conflicts between LLMs
- **Human-in-the-Loop**: Every decision approved by researchers with complete audit trail
- **Smart Caching**: Reuse recent results to minimize API costs (60-80% savings)
- **Direct API Integration**: Connect to PubMed, ClinicalTrials.gov, patent databases
- **Research Workflows**: Pre-built templates for common biotech research tasks
- **Analytics Dashboard**: Track performance, costs, and decision patterns

## ğŸ“‹ Prerequisites

- Node.js 18+ and npm
- Neon Postgres account (free tier)
- API keys for:
  - Anthropic (Claude)
  - OpenAI (GPT-4)
  - Google AI (Gemini)
  - xAI (Grok)

## ğŸ”§ Setup Instructions

### 1. Clone Repository

```bash
git clone <your-repo-url>
cd acm-research-agents
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Set Up Neon Database

1. Go to [neon.tech](https://neon.tech) and create a free account
2. Create a new project called "ACM Research Agents"
3. Copy the connection string (it looks like: `postgresql://user:pass@host.neon.tech/dbname`)
4. Run the database schema:

```bash
# Connect to your Neon database using psql or their web interface
# Copy and paste the contents of schema.sql
```

Or use the Neon SQL Editor in their dashboard to run `schema.sql`.

### 4. Configure Environment Variables

Create a `.env.local` file in the project root:

```bash
# Copy from .env.example
cp .env.example .env.local
```

Edit `.env.local` and add your credentials:

```env
# Database
DATABASE_URL=your_neon_postgres_connection_string_here

# LLM API Keys
ANTHROPIC_API_KEY=sk-ant-api03-...
OPENAI_API_KEY=sk-...
GOOGLE_AI_API_KEY=AIza...
XAI_API_KEY=xai-...

# App Configuration (optional)
NEXT_PUBLIC_APP_NAME=ACM Research Agents
NEXT_PUBLIC_APP_URL=http://localhost:3000
```

### 5. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸš¢ Deployment to Vercel

### Using Vercel CLI

1. Install Vercel CLI:

```bash
npm install -g vercel
```

2. Deploy:

```bash
vercel
```

3. Add environment variables in Vercel dashboard under Settings > Environment Variables

### Using GitHub Integration

1. Push code to GitHub:

```bash
git init
git add .
git commit -m "Initial commit"
git branch -M main
git remote add origin <your-github-repo-url>
git push -u origin main
```

2. Go to [vercel.com](https://vercel.com)
3. Click "Add New Project"
4. Import your GitHub repository
5. Add environment variables
6. Deploy!

## ğŸ“š Usage Guide

### Running Your First Query

1. **Navigate to Query Page**: Click "New Query" in the navigation
2. **Select Workflow** (optional): Choose from pre-built research workflows like:
   - Literature Mining & Synthesis
   - Target Identification & Validation
   - Clinical Trial Design
   - Regulatory Documentation
   - Competitive Intelligence
3. **Enter Your Question**: Type your research question
4. **Run Query**: Click "Run Query" - all 4 LLMs will respond in parallel
5. **Review Responses**: See side-by-side comparison with:
   - Response text
   - Confidence scores
   - Sources cited
   - Response times
   - Token usage
6. **Approve Decision**: Select which LLM's response to use or provide custom analysis

### Consensus Indicators

- **âœ… High Consensus**: All LLMs agree within 15 confidence points
- **âš ï¸ Medium Consensus**: Reasonable agreement (15-30 point spread)
- **âš ï¸ Conflict Detected**: Significant disagreement - human review required

### Cached Results

If you run the same query within 24 hours, you'll get cached results instantly (marked with âš¡ icon), saving API costs.

## ğŸ—ï¸ Project Structure

```
acm-research-agents/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ query/route.ts       # Main LLM orchestration endpoint
â”‚   â”‚   â”œâ”€â”€ workflows/route.ts    # Workflow management
â”‚   â”‚   â””â”€â”€ history/route.ts      # Query history (to be built)
â”‚   â”œâ”€â”€ query/page.tsx            # Main query interface
â”‚   â”œâ”€â”€ workflows/page.tsx        # Workflow management (to be built)
â”‚   â”œâ”€â”€ history/page.tsx          # Analytics dashboard (to be built)
â”‚   â”œâ”€â”€ layout.tsx                # Root layout
â”‚   â”œâ”€â”€ page.tsx                  # Home page
â”‚   â””â”€â”€ globals.css               # Global styles
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ db.ts                     # Database connection
â”‚   â”œâ”€â”€ llm-clients.ts            # LLM API clients
â”‚   â””â”€â”€ apis/                     # External API integrations (to be built)
â”œâ”€â”€ schema.sql                    # Database schema
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ README.md
```

## ğŸ’° Cost Estimates

Based on typical usage:

- **Claude API**: $50-200/month
- **OpenAI API**: $30-150/month
- **Gemini API**: $20-100/month
- **Grok API**: $30-120/month
- **Total**: $130-570/month

**Cost Optimization:**
- Response caching reduces costs by 60-80%
- Run in "Quick Mode" (Claude + GPT-4 only) for less critical queries
- Set usage limits per user/workflow

## ğŸ”’ Security Best Practices

1. **Never commit API keys** - use `.env.local` (already in .gitignore)
2. **Use Vercel Environment Variables** for production
3. **Implement authentication** - add auth before deploying to production
4. **Rate limiting** - add rate limits to API routes
5. **Input validation** - validate all user inputs

## ğŸ› ï¸ Development Roadmap

### Phase 1 (Current)
- âœ… Core multi-LLM orchestration
- âœ… Query interface with consensus detection
- âœ… Basic workflow management
- âœ… Response caching

### Phase 2 (Next 2 weeks)
- [ ] PubMed API integration
- [ ] ClinicalTrials.gov API integration
- [ ] History & analytics dashboard
- [ ] Human decision saving to database
- [ ] User authentication (Clerk or NextAuth)

### Phase 3 (Next 4 weeks)
- [ ] Advanced workflow builder
- [ ] PDF export of responses
- [ ] Email notifications for completed queries
- [ ] Team collaboration features
- [ ] Cost tracking dashboard

### Phase 4 (Next 6 weeks)
- [ ] Patent database integration
- [ ] Protein Data Bank integration
- [ ] Real-time streaming responses
- [ ] Custom LLM fine-tuning
- [ ] Mobile app (React Native)

## ğŸ¤ Contributing

This is a proprietary project for ACM Biolabs. For questions or support, contact:

**Jayaprakash Bandu**
- Email: [your-email]
- LinkedIn: [your-linkedin]

## ğŸ“ License

Proprietary - ACM Biolabs Â© 2025

## ğŸ™ Acknowledgments

- Built for Madhavan Nallani and the team at ACM Biolabs
- Inspired by proven airline operational intelligence frameworks
- Powered by Claude Sonnet 4.5, GPT-4o, Gemini 1.5 Pro, and Grok 2

---

**"Precision AI Architecture for Life-Saving Research"**
